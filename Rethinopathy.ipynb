{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rhweh1qSOYYH"
   },
   "source": [
    "# Wstępna analiza danych o retinopatii cukrzycowej\n",
    "\n",
    "Data Set został pobrany z repozytorium UCI (http://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set).\n",
    "Dane umieszczone tam są w formacie arff. W celu obsługi formatu należy użyć funkcję z pakietu SciPy oraz pakietu Pandas dla większego komfortu przeglądania informacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.689792Z",
     "start_time": "2020-05-31T15:56:08.685825Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "y1a4OEqFOYYI",
    "outputId": "2122e338-e182-40cc-9322-ba39bbe68c48"
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.723025Z",
     "start_time": "2020-05-31T15:56:08.690785Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "y1a4OEqFOYYI",
    "outputId": "2122e338-e182-40cc-9322-ba39bbe68c48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>49.895756</td>\n",
       "      <td>17.775994</td>\n",
       "      <td>5.270920</td>\n",
       "      <td>0.771761</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.486903</td>\n",
       "      <td>0.100025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>57.709936</td>\n",
       "      <td>23.799994</td>\n",
       "      <td>3.325423</td>\n",
       "      <td>0.234185</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>55.831441</td>\n",
       "      <td>27.993933</td>\n",
       "      <td>12.687485</td>\n",
       "      <td>4.852282</td>\n",
       "      <td>1.393889</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.530904</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.467228</td>\n",
       "      <td>18.445954</td>\n",
       "      <td>9.118901</td>\n",
       "      <td>3.079428</td>\n",
       "      <td>0.840261</td>\n",
       "      <td>0.272434</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.483284</td>\n",
       "      <td>0.114790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.026254</td>\n",
       "      <td>8.570709</td>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475935</td>\n",
       "      <td>0.123572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2     3     4     5     6     7          8          9  \\\n",
       "0  1.0  1.0  22.0  22.0  22.0  19.0  18.0  14.0  49.895756  17.775994   \n",
       "1  1.0  1.0  24.0  24.0  22.0  18.0  16.0  13.0  57.709936  23.799994   \n",
       "2  1.0  1.0  62.0  60.0  59.0  54.0  47.0  33.0  55.831441  27.993933   \n",
       "3  1.0  1.0  55.0  53.0  53.0  50.0  43.0  31.0  40.467228  18.445954   \n",
       "4  1.0  1.0  44.0  44.0  44.0  41.0  39.0  27.0  18.026254   8.570709   \n",
       "\n",
       "          10        11        12        13        14        15        16  \\\n",
       "0   5.270920  0.771761  0.018632  0.006864  0.003923  0.003923  0.486903   \n",
       "1   3.325423  0.234185  0.003903  0.003903  0.003903  0.003903  0.520908   \n",
       "2  12.687485  4.852282  1.393889  0.373252  0.041817  0.007744  0.530904   \n",
       "3   9.118901  3.079428  0.840261  0.272434  0.007653  0.001531  0.483284   \n",
       "4   0.410381  0.000000  0.000000  0.000000  0.000000  0.000000  0.475935   \n",
       "\n",
       "         17   18 Class  \n",
       "0  0.100025  1.0  b'0'  \n",
       "1  0.144414  0.0  b'0'  \n",
       "2  0.128548  0.0  b'1'  \n",
       "3  0.114790  0.0  b'0'  \n",
       "4  0.123572  0.0  b'1'  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = arff.loadarff('rethinpathy.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uekiBF-OYYN"
   },
   "source": [
    "## Oznaczenie kolumn\n",
    "0    - Oznaczenie jakości. 0 = zła jakość, 1 = dobra jakość<br>\n",
    "1    - Wynik poprzedniego badania tj. czy było robione coś wczesniej, z czym pacjent przychodzi do okulisty. 1 oznacza nieprawidłowość siatkówki<br>\n",
    "2-7  - Wynik wykrywania mikrotętniaków, wyrażone przez ilość takich poszerzeń naczynek<br>\n",
    "8-15 - Znormalizowany wynik badania ilości wysięków. Normalizacja następuje przez iloczyn średnicy obszaru przez obraz który się bada<br>\n",
    "16   - Znormalizowana odległość od środka plamki żółtej do środka tarczy nerwu wzrokowego <br>\n",
    "17   - Średnica tarczy nerwu wzrokowego<br>\n",
    "18   - Wyniki klasyfikacji patologicznych obrazów siatkówki za pomocą metody wykorzystującej modulacje amplitudy i częstotliwości<br>\n",
    "19   - 1 = występują oznaki retinopatii, 0 = nie występują"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c6idf2iMOYYO"
   },
   "source": [
    "Należy sprawdzić w jakim typie są zapisane dane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.728481Z",
     "start_time": "2020-05-31T15:56:08.724017Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "6fUhcuoAOYYO",
    "outputId": "49ba3177-8c0d-477a-df7a-804566b82901"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        float64\n",
       "1        float64\n",
       "2        float64\n",
       "3        float64\n",
       "4        float64\n",
       "5        float64\n",
       "6        float64\n",
       "7        float64\n",
       "8        float64\n",
       "9        float64\n",
       "10       float64\n",
       "11       float64\n",
       "12       float64\n",
       "13       float64\n",
       "14       float64\n",
       "15       float64\n",
       "16       float64\n",
       "17       float64\n",
       "18       float64\n",
       "Class     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tuErjRSNOYYS"
   },
   "source": [
    "Ponieważ część danych jest binarnych lub wyrażonych tylko liczbami naturalnymi, lepiej będzie gdy zostaną przedstawione tylko w postaci całkowitej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.744849Z",
     "start_time": "2020-05-31T15:56:08.729473Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "C-NBomjcOYYT",
    "outputId": "40a1158f-4171-41c3-b51f-2948bd60ae27"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>49.895756</td>\n",
       "      <td>17.775994</td>\n",
       "      <td>5.270920</td>\n",
       "      <td>0.771761</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.486903</td>\n",
       "      <td>0.100025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>57.709936</td>\n",
       "      <td>23.799994</td>\n",
       "      <td>3.325423</td>\n",
       "      <td>0.234185</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>55.831441</td>\n",
       "      <td>27.993933</td>\n",
       "      <td>12.687485</td>\n",
       "      <td>4.852282</td>\n",
       "      <td>1.393889</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.530904</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>40.467228</td>\n",
       "      <td>18.445954</td>\n",
       "      <td>9.118901</td>\n",
       "      <td>3.079428</td>\n",
       "      <td>0.840261</td>\n",
       "      <td>0.272434</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.483284</td>\n",
       "      <td>0.114790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>18.026254</td>\n",
       "      <td>8.570709</td>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475935</td>\n",
       "      <td>0.123572</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2   3   4   5   6   7          8          9         10        11  \\\n",
       "0  1  1  22  22  22  19  18  14  49.895756  17.775994   5.270920  0.771761   \n",
       "1  1  1  24  24  22  18  16  13  57.709936  23.799994   3.325423  0.234185   \n",
       "2  1  1  62  60  59  54  47  33  55.831441  27.993933  12.687485  4.852282   \n",
       "3  1  1  55  53  53  50  43  31  40.467228  18.445954   9.118901  3.079428   \n",
       "4  1  1  44  44  44  41  39  27  18.026254   8.570709   0.410381  0.000000   \n",
       "\n",
       "         12        13        14        15        16        17  18  Class  \n",
       "0  0.018632  0.006864  0.003923  0.003923  0.486903  0.100025   1      0  \n",
       "1  0.003903  0.003903  0.003903  0.003903  0.520908  0.144414   0      0  \n",
       "2  1.393889  0.373252  0.041817  0.007744  0.530904  0.128548   0      1  \n",
       "3  0.840261  0.272434  0.007653  0.001531  0.483284  0.114790   0      0  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.475935  0.123572   0      1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[0:8]] = df[df.columns[0:8]].astype(int)\n",
    "df[df.columns[18:20]] = df[df.columns[18:20]].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9KJAojsOYYX"
   },
   "source": [
    "Należy teraz nazwać kolumny by nadać sens zaimportowanemu zestawowi liczb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.757745Z",
     "start_time": "2020-05-31T15:56:08.745841Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "Dce4HutROYYY",
    "outputId": "c4ffcca5-4dfd-405e-d9a7-25883e68e184"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>Pre-screening</th>\n",
       "      <th>MA result1</th>\n",
       "      <th>MA result2</th>\n",
       "      <th>MA result3</th>\n",
       "      <th>MA result4</th>\n",
       "      <th>MA result5</th>\n",
       "      <th>MA result6</th>\n",
       "      <th>Exudates result1</th>\n",
       "      <th>Exudates result2</th>\n",
       "      <th>Exudates result3</th>\n",
       "      <th>Exudates result4</th>\n",
       "      <th>Exudates result5</th>\n",
       "      <th>Exudates result6</th>\n",
       "      <th>Exudates result7</th>\n",
       "      <th>Exudates result</th>\n",
       "      <th>Macula - Optic disc dist</th>\n",
       "      <th>Optic disc diameter</th>\n",
       "      <th>AM/FM classification</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>49.895756</td>\n",
       "      <td>17.775994</td>\n",
       "      <td>5.270920</td>\n",
       "      <td>0.771761</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.486903</td>\n",
       "      <td>0.100025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>57.709936</td>\n",
       "      <td>23.799994</td>\n",
       "      <td>3.325423</td>\n",
       "      <td>0.234185</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>55.831441</td>\n",
       "      <td>27.993933</td>\n",
       "      <td>12.687485</td>\n",
       "      <td>4.852282</td>\n",
       "      <td>1.393889</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.530904</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>40.467228</td>\n",
       "      <td>18.445954</td>\n",
       "      <td>9.118901</td>\n",
       "      <td>3.079428</td>\n",
       "      <td>0.840261</td>\n",
       "      <td>0.272434</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.483284</td>\n",
       "      <td>0.114790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>18.026254</td>\n",
       "      <td>8.570709</td>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475935</td>\n",
       "      <td>0.123572</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quality  Pre-screening  MA result1  MA result2  MA result3  MA result4  \\\n",
       "0        1              1          22          22          22          19   \n",
       "1        1              1          24          24          22          18   \n",
       "2        1              1          62          60          59          54   \n",
       "3        1              1          55          53          53          50   \n",
       "4        1              1          44          44          44          41   \n",
       "\n",
       "   MA result5  MA result6  Exudates result1  Exudates result2  \\\n",
       "0          18          14         49.895756         17.775994   \n",
       "1          16          13         57.709936         23.799994   \n",
       "2          47          33         55.831441         27.993933   \n",
       "3          43          31         40.467228         18.445954   \n",
       "4          39          27         18.026254          8.570709   \n",
       "\n",
       "   Exudates result3  Exudates result4  Exudates result5  Exudates result6  \\\n",
       "0          5.270920          0.771761          0.018632          0.006864   \n",
       "1          3.325423          0.234185          0.003903          0.003903   \n",
       "2         12.687485          4.852282          1.393889          0.373252   \n",
       "3          9.118901          3.079428          0.840261          0.272434   \n",
       "4          0.410381          0.000000          0.000000          0.000000   \n",
       "\n",
       "   Exudates result7  Exudates result  Macula - Optic disc dist  \\\n",
       "0          0.003923         0.003923                  0.486903   \n",
       "1          0.003903         0.003903                  0.520908   \n",
       "2          0.041817         0.007744                  0.530904   \n",
       "3          0.007653         0.001531                  0.483284   \n",
       "4          0.000000         0.000000                  0.475935   \n",
       "\n",
       "   Optic disc diameter  AM/FM classification  Class  \n",
       "0             0.100025                     1      0  \n",
       "1             0.144414                     0      0  \n",
       "2             0.128548                     0      1  \n",
       "3             0.114790                     0      0  \n",
       "4             0.123572                     0      1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['Quality', 'Pre-screening', 'MA result1', 'MA result2', 'MA result3', 'MA result4', 'MA result5', 'MA result6', 'Exudates result1', 'Exudates result2', 'Exudates result3', 'Exudates result4', 'Exudates result5', 'Exudates result6', 'Exudates result7',\n",
    "            'Exudates result', 'Macula - Optic disc dist', 'Optic disc diameter', 'AM/FM classification', 'Class']\n",
    "df.columns = col_names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.762209Z",
     "start_time": "2020-05-31T15:56:08.758241Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PSNU-hZHOYYb",
    "outputId": "03487f10-d799-4b83-a36e-60a28e71c4fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LoRA7B_1OYYe"
   },
   "source": [
    "# 2 zadanie\n",
    "\n",
    "By rozwiązać problem klasyfikacji danych należy odpowiednio przygotować dataset. Najpierw przypisuje do nowego dataframe'u wszystkie kolumny prócz ostatniej żeby oddzielić dane od wyniku.\n",
    "Ostatnia kolumna jest zapisywana do oddzielnej zmiennej jako wynik klasyfikacji.\n",
    "W ostantim kroku dataframe jest rozdzielany na dane treningowe i dane testowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.782049Z",
     "start_time": "2020-05-31T15:56:08.763201Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "LpQe-kdyOYYf",
    "outputId": "fa11036c-657b-4118-fd97-f9c1c853453e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>Pre-screening</th>\n",
       "      <th>MA result1</th>\n",
       "      <th>MA result2</th>\n",
       "      <th>MA result3</th>\n",
       "      <th>MA result4</th>\n",
       "      <th>MA result5</th>\n",
       "      <th>MA result6</th>\n",
       "      <th>Exudates result1</th>\n",
       "      <th>Exudates result2</th>\n",
       "      <th>Exudates result3</th>\n",
       "      <th>Exudates result4</th>\n",
       "      <th>Exudates result5</th>\n",
       "      <th>Exudates result6</th>\n",
       "      <th>Exudates result7</th>\n",
       "      <th>Exudates result</th>\n",
       "      <th>Macula - Optic disc dist</th>\n",
       "      <th>Optic disc diameter</th>\n",
       "      <th>AM/FM classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-0.641486</td>\n",
       "      <td>-0.618782</td>\n",
       "      <td>-0.576463</td>\n",
       "      <td>-0.630029</td>\n",
       "      <td>-0.551116</td>\n",
       "      <td>-0.473745</td>\n",
       "      <td>-0.242917</td>\n",
       "      <td>-0.246003</td>\n",
       "      <td>-0.296966</td>\n",
       "      <td>-0.271509</td>\n",
       "      <td>-0.218324</td>\n",
       "      <td>-0.194409</td>\n",
       "      <td>-0.205124</td>\n",
       "      <td>-0.186169</td>\n",
       "      <td>-1.294763</td>\n",
       "      <td>-0.468656</td>\n",
       "      <td>1.405048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-0.563391</td>\n",
       "      <td>-0.535778</td>\n",
       "      <td>-0.576463</td>\n",
       "      <td>-0.677410</td>\n",
       "      <td>-0.653676</td>\n",
       "      <td>-0.539992</td>\n",
       "      <td>-0.109250</td>\n",
       "      <td>0.032972</td>\n",
       "      <td>-0.465224</td>\n",
       "      <td>-0.408593</td>\n",
       "      <td>-0.224256</td>\n",
       "      <td>-0.197212</td>\n",
       "      <td>-0.205175</td>\n",
       "      <td>-0.186281</td>\n",
       "      <td>-0.082168</td>\n",
       "      <td>2.006054</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.920417</td>\n",
       "      <td>0.958299</td>\n",
       "      <td>1.046665</td>\n",
       "      <td>1.028299</td>\n",
       "      <td>0.936006</td>\n",
       "      <td>0.784951</td>\n",
       "      <td>-0.141383</td>\n",
       "      <td>0.227196</td>\n",
       "      <td>0.344463</td>\n",
       "      <td>0.769037</td>\n",
       "      <td>0.335538</td>\n",
       "      <td>0.152330</td>\n",
       "      <td>-0.110043</td>\n",
       "      <td>-0.164808</td>\n",
       "      <td>0.274283</td>\n",
       "      <td>1.121516</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.647084</td>\n",
       "      <td>0.667784</td>\n",
       "      <td>0.783456</td>\n",
       "      <td>0.838776</td>\n",
       "      <td>0.730886</td>\n",
       "      <td>0.652456</td>\n",
       "      <td>-0.404199</td>\n",
       "      <td>-0.214977</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>0.316953</td>\n",
       "      <td>0.112573</td>\n",
       "      <td>0.056919</td>\n",
       "      <td>-0.195765</td>\n",
       "      <td>-0.199541</td>\n",
       "      <td>-1.423814</td>\n",
       "      <td>0.354501</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.217561</td>\n",
       "      <td>0.294265</td>\n",
       "      <td>0.388641</td>\n",
       "      <td>0.412349</td>\n",
       "      <td>0.525766</td>\n",
       "      <td>0.387468</td>\n",
       "      <td>-0.788069</td>\n",
       "      <td>-0.672306</td>\n",
       "      <td>-0.717335</td>\n",
       "      <td>-0.468311</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>-1.685874</td>\n",
       "      <td>0.844102</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-0.172915</td>\n",
       "      <td>-0.120756</td>\n",
       "      <td>-0.050043</td>\n",
       "      <td>0.033302</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.188727</td>\n",
       "      <td>-0.992560</td>\n",
       "      <td>-1.025806</td>\n",
       "      <td>-0.750133</td>\n",
       "      <td>-0.467516</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>0.508422</td>\n",
       "      <td>0.466281</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.412798</td>\n",
       "      <td>0.501776</td>\n",
       "      <td>0.607982</td>\n",
       "      <td>0.791395</td>\n",
       "      <td>0.833446</td>\n",
       "      <td>1.049939</td>\n",
       "      <td>-0.015387</td>\n",
       "      <td>0.198657</td>\n",
       "      <td>-0.055085</td>\n",
       "      <td>-0.218523</td>\n",
       "      <td>-0.225203</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>-0.231045</td>\n",
       "      <td>0.878556</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>-3.353309</td>\n",
       "      <td>0.412798</td>\n",
       "      <td>0.460274</td>\n",
       "      <td>0.564114</td>\n",
       "      <td>0.601872</td>\n",
       "      <td>0.730886</td>\n",
       "      <td>0.784951</td>\n",
       "      <td>-0.575348</td>\n",
       "      <td>-0.422401</td>\n",
       "      <td>-0.600326</td>\n",
       "      <td>-0.433156</td>\n",
       "      <td>-0.221309</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>1.334363</td>\n",
       "      <td>1.193713</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>-0.037752</td>\n",
       "      <td>-0.269384</td>\n",
       "      <td>-0.440506</td>\n",
       "      <td>-0.807516</td>\n",
       "      <td>-0.937474</td>\n",
       "      <td>-0.403199</td>\n",
       "      <td>-0.485477</td>\n",
       "      <td>-0.342804</td>\n",
       "      <td>-0.193527</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.108426</td>\n",
       "      <td>0.386140</td>\n",
       "      <td>0.767878</td>\n",
       "      <td>-1.327962</td>\n",
       "      <td>-0.097078</td>\n",
       "      <td>1.405048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-1.227200</td>\n",
       "      <td>-1.241314</td>\n",
       "      <td>-1.234487</td>\n",
       "      <td>-1.198599</td>\n",
       "      <td>-1.115197</td>\n",
       "      <td>-1.069968</td>\n",
       "      <td>0.091120</td>\n",
       "      <td>-0.743572</td>\n",
       "      <td>-0.601429</td>\n",
       "      <td>-0.456428</td>\n",
       "      <td>-0.217298</td>\n",
       "      <td>-0.192888</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>1.176035</td>\n",
       "      <td>-1.085702</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1151 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Quality  Pre-screening  MA result1  MA result2  MA result3  MA result4  \\\n",
       "0     0.059054       0.298213   -0.641486   -0.618782   -0.576463   -0.630029   \n",
       "1     0.059054       0.298213   -0.563391   -0.535778   -0.576463   -0.677410   \n",
       "2     0.059054       0.298213    0.920417    0.958299    1.046665    1.028299   \n",
       "3     0.059054       0.298213    0.647084    0.667784    0.783456    0.838776   \n",
       "4     0.059054       0.298213    0.217561    0.294265    0.388641    0.412349   \n",
       "...        ...            ...         ...         ...         ...         ...   \n",
       "1146  0.059054       0.298213   -0.172915   -0.120756   -0.050043    0.033302   \n",
       "1147  0.059054       0.298213    0.412798    0.501776    0.607982    0.791395   \n",
       "1148  0.059054      -3.353309    0.412798    0.460274    0.564114    0.601872   \n",
       "1149  0.059054       0.298213    0.022323   -0.037752   -0.269384   -0.440506   \n",
       "1150  0.059054       0.298213   -1.227200   -1.241314   -1.234487   -1.198599   \n",
       "\n",
       "      MA result5  MA result6  Exudates result1  Exudates result2  \\\n",
       "0      -0.551116   -0.473745         -0.242917         -0.246003   \n",
       "1      -0.653676   -0.539992         -0.109250          0.032972   \n",
       "2       0.936006    0.784951         -0.141383          0.227196   \n",
       "3       0.730886    0.652456         -0.404199         -0.214977   \n",
       "4       0.525766    0.387468         -0.788069         -0.672306   \n",
       "...          ...         ...               ...               ...   \n",
       "1146    0.115525    0.188727         -0.992560         -1.025806   \n",
       "1147    0.833446    1.049939         -0.015387          0.198657   \n",
       "1148    0.730886    0.784951         -0.575348         -0.422401   \n",
       "1149   -0.807516   -0.937474         -0.403199         -0.485477   \n",
       "1150   -1.115197   -1.069968          0.091120         -0.743572   \n",
       "\n",
       "      Exudates result3  Exudates result4  Exudates result5  Exudates result6  \\\n",
       "0            -0.296966         -0.271509         -0.218324         -0.194409   \n",
       "1            -0.465224         -0.408593         -0.224256         -0.197212   \n",
       "2             0.344463          0.769037          0.335538          0.152330   \n",
       "3             0.035830          0.316953          0.112573          0.056919   \n",
       "4            -0.717335         -0.468311         -0.225828         -0.200905   \n",
       "...                ...               ...               ...               ...   \n",
       "1146         -0.750133         -0.467516         -0.225828         -0.200905   \n",
       "1147         -0.055085         -0.218523         -0.225203         -0.200905   \n",
       "1148         -0.600326         -0.433156         -0.221309         -0.200905   \n",
       "1149         -0.342804         -0.193527          0.001120          0.108426   \n",
       "1150         -0.601429         -0.456428         -0.217298         -0.192888   \n",
       "\n",
       "      Exudates result7  Exudates result  Macula - Optic disc dist  \\\n",
       "0            -0.205124        -0.186169                 -1.294763   \n",
       "1            -0.205175        -0.186281                 -0.082168   \n",
       "2            -0.110043        -0.164808                  0.274283   \n",
       "3            -0.195765        -0.199541                 -1.423814   \n",
       "4            -0.214968        -0.208100                 -1.685874   \n",
       "...                ...              ...                       ...   \n",
       "1146         -0.214968        -0.208100                  0.508422   \n",
       "1147         -0.214968        -0.208100                 -0.231045   \n",
       "1148         -0.214968        -0.208100                  1.334363   \n",
       "1149          0.386140         0.767878                 -1.327962   \n",
       "1150         -0.214968        -0.208100                  1.176035   \n",
       "\n",
       "      Optic disc diameter  AM/FM classification  \n",
       "0               -0.468656              1.405048  \n",
       "1                2.006054             -0.711719  \n",
       "2                1.121516             -0.711719  \n",
       "3                0.354501             -0.711719  \n",
       "4                0.844102             -0.711719  \n",
       "...                   ...                   ...  \n",
       "1146             0.466281             -0.711719  \n",
       "1147             0.878556             -0.711719  \n",
       "1148             1.193713             -0.711719  \n",
       "1149            -0.097078              1.405048  \n",
       "1150            -1.085702             -0.711719  \n",
       "\n",
       "[1151 rows x 19 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizacja danych\n",
    "\n",
    "data = df[df.columns[0:19]]\n",
    "target = df['Class']\n",
    "\n",
    "col_names = ['Quality', 'Pre-screening', 'MA result1', 'MA result2', 'MA result3', 'MA result4', 'MA result5', 'MA result6', 'Exudates result1', 'Exudates result2', 'Exudates result3', 'Exudates result4', 'Exudates result5', 'Exudates result6', 'Exudates result7',\n",
    "             'Exudates result', 'Macula - Optic disc dist', 'Optic disc diameter', 'AM/FM classification']\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data, columns=col_names)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.785521Z",
     "start_time": "2020-05-31T15:56:08.783537Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1793
    },
    "colab_type": "code",
    "id": "x1pj6jrmSkJO",
    "outputId": "69d94777-15a2-4005-a70c-a7ae3f53b8b3"
   },
   "outputs": [],
   "source": [
    "# !pip install feature_selector\n",
    "# from feature_selector import FeatureSelector\n",
    "# Features are in train and labels are in train_labels\n",
    "# fs = FeatureSelector(data = data, labels = target)\n",
    "# Pass in the appropriate parameters\n",
    "# fs.identify_zero_importance(task = 'classification',\n",
    "#                            eval_metric = 'auc',\n",
    "#                            n_iterations = 10,\n",
    "#                             early_stopping = True)\n",
    "# list of zero importance features\n",
    "# zero_importance_features = fs.ops['zero_importance']\n",
    "# plot the feature importances\n",
    "# fs.plot_feature_importances(threshold = 0.99, plot_n = 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.790481Z",
     "start_time": "2020-05-31T15:56:08.786513Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K9UhG8xoOYYi",
    "outputId": "de8af9ff-e6db-4c74-ae09-2dec7f76f844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.08427454387489"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % chorych\n",
    "target[target == 1].count() / target.count() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.794945Z",
     "start_time": "2020-05-31T15:56:08.791473Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Db4mbS1COYYk"
   },
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ruV8nEOWOYYm"
   },
   "source": [
    "Pierwszym wykorzystanym algorytmem będzie naiwny klasyfikator bayesowski."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.800401Z",
     "start_time": "2020-05-31T15:56:08.795937Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pRlumuKCOYYo",
    "outputId": "b83b0735-88d1-487e-fae0-61edd6330eb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes acc:  0.658008658008658\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "pred = gnb.fit(data_train, target_train).predict(data_test)\n",
    "print(\"Naive-Bayes acc: \", accuracy_score(target_test, pred, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLRWXufIOYYr"
   },
   "source": [
    "Wynik wychodzi słaby więc nie będzie to efektywny algorytm do tych danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rF1EohiaOYYs"
   },
   "source": [
    "Następnym sprawdzonym algorytmem będzie klasyfikacja liniowym wektorem nośnym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.945729Z",
     "start_time": "2020-05-31T15:56:08.801393Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "N8miIu-pOYYt",
    "outputId": "0d2a3416-5da4-4850-dc0c-21eadf62b455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC acc:  0.7316017316017316\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "BLOK WYKONUJE SIE OKOLO 3 MIN\n",
    "'''\n",
    "svc_model = LinearSVC(random_state=0, max_iter=10000000)\n",
    "\n",
    "pred = svc_model.fit(data_train, target_train).predict(data_test)\n",
    "\n",
    "print(\"LinearSVC acc: \", accuracy_score(target_test, pred, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:08.948705Z",
     "start_time": "2020-05-31T15:56:08.946723Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "epH9-bLXWTn4",
    "outputId": "bcc29a45-9e8c-4652-edb0-5bc69eefa0f0"
   },
   "outputs": [],
   "source": [
    "# data = data.drop(columns =['Macula - Optic disc dist', 'Optic disc diameter'])\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# data = sc.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZcZEEGrqOYYw"
   },
   "source": [
    "Ostatnim sprawdzonym algorytmem będzie K najbliższych sąsiadów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:56:16.916448Z",
     "start_time": "2020-05-31T15:56:16.901568Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y3zBf5kMOYYx",
    "outputId": "c5de5240-f710-41c1-f5c6-e8e7ea5b6ff0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy:  0.6147186147186147\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(data_train,  target_train)\n",
    "pred = knn.predict(data_test)\n",
    "print(\"KNN accuracy: \", accuracy_score(target_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTnJCTsKOYY0"
   },
   "source": [
    "Precyzja jest znacznie lepsza od poprzednich algorytmów ale dalej wyniki nie są zadowalające."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:37:44.607222Z",
     "start_time": "2020-05-16T10:37:28.469869Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10217
    },
    "colab_type": "code",
    "id": "eFKcJpOfOYY1",
    "outputId": "13f50192-4ba8-4708-83c0-6348ae4931c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "920/920 [==============================] - 0s 108us/step - loss: 0.6929 - accuracy: 0.5087\n",
      "Epoch 2/1000\n",
      "920/920 [==============================] - 0s 19us/step - loss: 0.6933 - accuracy: 0.5217\n",
      "Epoch 3/1000\n",
      "920/920 [==============================] - 0s 19us/step - loss: 0.6923 - accuracy: 0.5217\n",
      "Epoch 4/1000\n",
      "920/920 [==============================] - 0s 18us/step - loss: 0.6906 - accuracy: 0.5217\n",
      "Epoch 5/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.6764 - accuracy: 0.5446\n",
      "Epoch 6/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.6358 - accuracy: 0.6533\n",
      "Epoch 7/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.6046 - accuracy: 0.6859\n",
      "Epoch 8/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5921 - accuracy: 0.6913\n",
      "Epoch 9/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5873 - accuracy: 0.6989\n",
      "Epoch 10/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5861 - accuracy: 0.7011\n",
      "Epoch 11/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5800 - accuracy: 0.7043\n",
      "Epoch 12/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5785 - accuracy: 0.7076\n",
      "Epoch 13/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5761 - accuracy: 0.7163\n",
      "Epoch 14/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5754 - accuracy: 0.7120\n",
      "Epoch 15/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5783 - accuracy: 0.7109\n",
      "Epoch 16/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5734 - accuracy: 0.7043\n",
      "Epoch 17/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5741 - accuracy: 0.7130\n",
      "Epoch 18/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5754 - accuracy: 0.7098\n",
      "Epoch 19/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5687 - accuracy: 0.7120\n",
      "Epoch 20/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5677 - accuracy: 0.7130\n",
      "Epoch 21/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5686 - accuracy: 0.7130\n",
      "Epoch 22/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5641 - accuracy: 0.7196\n",
      "Epoch 23/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5645 - accuracy: 0.7130\n",
      "Epoch 24/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5589 - accuracy: 0.7130\n",
      "Epoch 25/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5530 - accuracy: 0.7109\n",
      "Epoch 26/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5485 - accuracy: 0.7109\n",
      "Epoch 27/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5407 - accuracy: 0.7272\n",
      "Epoch 28/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5395 - accuracy: 0.7207\n",
      "Epoch 29/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5329 - accuracy: 0.7293\n",
      "Epoch 30/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5253 - accuracy: 0.7326\n",
      "Epoch 31/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5247 - accuracy: 0.7391\n",
      "Epoch 32/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5202 - accuracy: 0.7370\n",
      "Epoch 33/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4994 - accuracy: 0.7554\n",
      "Epoch 34/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4999 - accuracy: 0.7424\n",
      "Epoch 35/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5078 - accuracy: 0.7370\n",
      "Epoch 36/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.5023 - accuracy: 0.7467\n",
      "Epoch 37/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4810 - accuracy: 0.7739\n",
      "Epoch 38/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4797 - accuracy: 0.7598\n",
      "Epoch 39/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4768 - accuracy: 0.7750\n",
      "Epoch 40/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4758 - accuracy: 0.7663\n",
      "Epoch 41/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4812 - accuracy: 0.7554\n",
      "Epoch 42/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4680 - accuracy: 0.7761\n",
      "Epoch 43/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4673 - accuracy: 0.7750\n",
      "Epoch 44/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4707 - accuracy: 0.7685\n",
      "Epoch 45/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4697 - accuracy: 0.7739\n",
      "Epoch 46/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4700 - accuracy: 0.7565\n",
      "Epoch 47/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4694 - accuracy: 0.7728\n",
      "Epoch 48/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4617 - accuracy: 0.7609\n",
      "Epoch 49/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4582 - accuracy: 0.7793\n",
      "Epoch 50/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4554 - accuracy: 0.7815\n",
      "Epoch 51/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4568 - accuracy: 0.7848\n",
      "Epoch 52/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4700 - accuracy: 0.7793\n",
      "Epoch 53/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4612 - accuracy: 0.7804\n",
      "Epoch 54/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4646 - accuracy: 0.7685\n",
      "Epoch 55/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4564 - accuracy: 0.7717\n",
      "Epoch 56/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4600 - accuracy: 0.7663\n",
      "Epoch 57/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4529 - accuracy: 0.7815\n",
      "Epoch 58/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4545 - accuracy: 0.7793\n",
      "Epoch 59/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4535 - accuracy: 0.7837\n",
      "Epoch 60/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4535 - accuracy: 0.7870\n",
      "Epoch 61/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4588 - accuracy: 0.7804\n",
      "Epoch 62/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4470 - accuracy: 0.7870\n",
      "Epoch 63/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4453 - accuracy: 0.7826\n",
      "Epoch 64/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4462 - accuracy: 0.7859\n",
      "Epoch 65/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4437 - accuracy: 0.7924\n",
      "Epoch 66/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4450 - accuracy: 0.7793\n",
      "Epoch 67/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4435 - accuracy: 0.7750\n",
      "Epoch 68/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4444 - accuracy: 0.7913\n",
      "Epoch 69/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4434 - accuracy: 0.7783\n",
      "Epoch 70/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4510 - accuracy: 0.7859\n",
      "Epoch 71/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4470 - accuracy: 0.7880\n",
      "Epoch 72/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4503 - accuracy: 0.7837\n",
      "Epoch 73/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4430 - accuracy: 0.8011\n",
      "Epoch 74/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4487 - accuracy: 0.7859\n",
      "Epoch 75/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4391 - accuracy: 0.7978\n",
      "Epoch 76/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4429 - accuracy: 0.7924\n",
      "Epoch 77/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4456 - accuracy: 0.7880\n",
      "Epoch 78/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4446 - accuracy: 0.7902\n",
      "Epoch 79/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4626 - accuracy: 0.7707\n",
      "Epoch 80/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4438 - accuracy: 0.7859\n",
      "Epoch 81/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4449 - accuracy: 0.7837\n",
      "Epoch 82/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4367 - accuracy: 0.7978\n",
      "Epoch 83/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4485 - accuracy: 0.7848\n",
      "Epoch 84/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4362 - accuracy: 0.7935\n",
      "Epoch 85/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4403 - accuracy: 0.7859\n",
      "Epoch 86/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4437 - accuracy: 0.7880\n",
      "Epoch 87/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4330 - accuracy: 0.7957\n",
      "Epoch 88/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4337 - accuracy: 0.8011\n",
      "Epoch 89/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4338 - accuracy: 0.7880\n",
      "Epoch 90/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4331 - accuracy: 0.7946\n",
      "Epoch 91/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4358 - accuracy: 0.7880\n",
      "Epoch 92/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4356 - accuracy: 0.7891\n",
      "Epoch 93/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4368 - accuracy: 0.7859\n",
      "Epoch 94/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4436 - accuracy: 0.7870\n",
      "Epoch 95/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4284 - accuracy: 0.8043\n",
      "Epoch 96/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4279 - accuracy: 0.7891\n",
      "Epoch 97/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4285 - accuracy: 0.7902\n",
      "Epoch 98/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4259 - accuracy: 0.8033\n",
      "Epoch 99/1000\n",
      "920/920 [==============================] - 0s 22us/step - loss: 0.4311 - accuracy: 0.7837\n",
      "Epoch 100/1000\n",
      "920/920 [==============================] - 0s 19us/step - loss: 0.4379 - accuracy: 0.7870\n",
      "Epoch 101/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4309 - accuracy: 0.7967\n",
      "Epoch 102/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4261 - accuracy: 0.7978\n",
      "Epoch 103/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4325 - accuracy: 0.8000\n",
      "Epoch 104/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4348 - accuracy: 0.8022\n",
      "Epoch 105/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4298 - accuracy: 0.8043\n",
      "Epoch 106/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4326 - accuracy: 0.7989\n",
      "Epoch 107/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4409 - accuracy: 0.7870\n",
      "Epoch 108/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4370 - accuracy: 0.7837\n",
      "Epoch 109/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4307 - accuracy: 0.7913\n",
      "Epoch 110/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4328 - accuracy: 0.7826\n",
      "Epoch 111/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4335 - accuracy: 0.7957\n",
      "Epoch 112/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4307 - accuracy: 0.7924\n",
      "Epoch 113/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4285 - accuracy: 0.7957\n",
      "Epoch 114/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4262 - accuracy: 0.7989\n",
      "Epoch 115/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4231 - accuracy: 0.7924\n",
      "Epoch 116/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4202 - accuracy: 0.7967\n",
      "Epoch 117/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4312 - accuracy: 0.7804\n",
      "Epoch 118/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4253 - accuracy: 0.8011\n",
      "Epoch 119/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4273 - accuracy: 0.8120\n",
      "Epoch 120/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4252 - accuracy: 0.7935\n",
      "Epoch 121/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4307 - accuracy: 0.8000\n",
      "Epoch 122/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4340 - accuracy: 0.7891\n",
      "Epoch 123/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4305 - accuracy: 0.7913\n",
      "Epoch 124/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4482 - accuracy: 0.7837\n",
      "Epoch 125/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4258 - accuracy: 0.8000\n",
      "Epoch 126/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4350 - accuracy: 0.7902\n",
      "Epoch 127/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4279 - accuracy: 0.8011\n",
      "Epoch 128/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4271 - accuracy: 0.7978\n",
      "Epoch 129/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4218 - accuracy: 0.8022\n",
      "Epoch 130/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4222 - accuracy: 0.7957\n",
      "Epoch 131/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4262 - accuracy: 0.7913\n",
      "Epoch 132/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4220 - accuracy: 0.8043\n",
      "Epoch 133/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4264 - accuracy: 0.7957\n",
      "Epoch 134/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4193 - accuracy: 0.8033\n",
      "Epoch 135/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4257 - accuracy: 0.8011\n",
      "Epoch 136/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4180 - accuracy: 0.8000\n",
      "Epoch 137/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4190 - accuracy: 0.8000\n",
      "Epoch 138/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4179 - accuracy: 0.8022\n",
      "Epoch 139/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4308 - accuracy: 0.7946\n",
      "Epoch 140/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4163 - accuracy: 0.7989\n",
      "Epoch 141/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4221 - accuracy: 0.8000\n",
      "Epoch 142/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4241 - accuracy: 0.7957\n",
      "Epoch 143/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4181 - accuracy: 0.8000\n",
      "Epoch 144/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4194 - accuracy: 0.8054\n",
      "Epoch 145/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4136 - accuracy: 0.8120\n",
      "Epoch 146/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4156 - accuracy: 0.8065\n",
      "Epoch 147/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4228 - accuracy: 0.8076\n",
      "Epoch 148/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4199 - accuracy: 0.8043\n",
      "Epoch 149/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4192 - accuracy: 0.8076\n",
      "Epoch 150/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4134 - accuracy: 0.8054\n",
      "Epoch 151/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4312 - accuracy: 0.7804\n",
      "Epoch 152/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4278 - accuracy: 0.7989\n",
      "Epoch 153/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4203 - accuracy: 0.8033\n",
      "Epoch 154/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4154 - accuracy: 0.8098\n",
      "Epoch 155/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4232 - accuracy: 0.8054\n",
      "Epoch 156/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4155 - accuracy: 0.8087\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920/920 [==============================] - 0s 16us/step - loss: 0.4175 - accuracy: 0.8076\n",
      "Epoch 158/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4137 - accuracy: 0.8033\n",
      "Epoch 159/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4123 - accuracy: 0.8076\n",
      "Epoch 160/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4170 - accuracy: 0.7978\n",
      "Epoch 161/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4115 - accuracy: 0.8065\n",
      "Epoch 162/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4164 - accuracy: 0.8109\n",
      "Epoch 163/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4110 - accuracy: 0.8120\n",
      "Epoch 164/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4107 - accuracy: 0.8098\n",
      "Epoch 165/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4141 - accuracy: 0.8174\n",
      "Epoch 166/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4147 - accuracy: 0.8098\n",
      "Epoch 167/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4203 - accuracy: 0.8011\n",
      "Epoch 168/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4236 - accuracy: 0.7848\n",
      "Epoch 169/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4228 - accuracy: 0.7957\n",
      "Epoch 170/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4209 - accuracy: 0.7978\n",
      "Epoch 171/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4145 - accuracy: 0.8022\n",
      "Epoch 172/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4188 - accuracy: 0.8043\n",
      "Epoch 173/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4087 - accuracy: 0.8076\n",
      "Epoch 174/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4112 - accuracy: 0.8065\n",
      "Epoch 175/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4139 - accuracy: 0.8022\n",
      "Epoch 176/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4143 - accuracy: 0.8043\n",
      "Epoch 177/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4100 - accuracy: 0.8098\n",
      "Epoch 178/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4107 - accuracy: 0.8098\n",
      "Epoch 179/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4103 - accuracy: 0.8043\n",
      "Epoch 180/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4155 - accuracy: 0.8141\n",
      "Epoch 181/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4123 - accuracy: 0.7978\n",
      "Epoch 182/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4255 - accuracy: 0.7946\n",
      "Epoch 183/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4224 - accuracy: 0.8098\n",
      "Epoch 184/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4173 - accuracy: 0.8011\n",
      "Epoch 185/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4179 - accuracy: 0.7989\n",
      "Epoch 186/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4135 - accuracy: 0.8065\n",
      "Epoch 187/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4057 - accuracy: 0.8043\n",
      "Epoch 188/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4155 - accuracy: 0.8022\n",
      "Epoch 189/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4195 - accuracy: 0.7891\n",
      "Epoch 190/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4151 - accuracy: 0.8022\n",
      "Epoch 191/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4127 - accuracy: 0.7913\n",
      "Epoch 192/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4125 - accuracy: 0.8054\n",
      "Epoch 193/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4132 - accuracy: 0.8087\n",
      "Epoch 194/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4165 - accuracy: 0.8076\n",
      "Epoch 195/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4135 - accuracy: 0.8033\n",
      "Epoch 196/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4037 - accuracy: 0.8163\n",
      "Epoch 197/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4088 - accuracy: 0.8152\n",
      "Epoch 198/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4133 - accuracy: 0.8043\n",
      "Epoch 199/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4097 - accuracy: 0.7913\n",
      "Epoch 200/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4081 - accuracy: 0.8054\n",
      "Epoch 201/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4161 - accuracy: 0.7848\n",
      "Epoch 202/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4135 - accuracy: 0.7989\n",
      "Epoch 203/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4022 - accuracy: 0.8196\n",
      "Epoch 204/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4113 - accuracy: 0.8043\n",
      "Epoch 205/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4069 - accuracy: 0.8109\n",
      "Epoch 206/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4081 - accuracy: 0.8065\n",
      "Epoch 207/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4158 - accuracy: 0.8152\n",
      "Epoch 208/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4096 - accuracy: 0.8098\n",
      "Epoch 209/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4115 - accuracy: 0.8174\n",
      "Epoch 210/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4061 - accuracy: 0.8152\n",
      "Epoch 211/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4085 - accuracy: 0.8098\n",
      "Epoch 212/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4168 - accuracy: 0.8043\n",
      "Epoch 213/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4103 - accuracy: 0.8109\n",
      "Epoch 214/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4043 - accuracy: 0.8022\n",
      "Epoch 215/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4076 - accuracy: 0.8120\n",
      "Epoch 216/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4082 - accuracy: 0.7978\n",
      "Epoch 217/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4109 - accuracy: 0.8076\n",
      "Epoch 218/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4020 - accuracy: 0.8076\n",
      "Epoch 219/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4088 - accuracy: 0.8109\n",
      "Epoch 220/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4082 - accuracy: 0.8054\n",
      "Epoch 221/1000\n",
      "920/920 [==============================] - 0s 18us/step - loss: 0.4055 - accuracy: 0.8022\n",
      "Epoch 222/1000\n",
      "920/920 [==============================] - 0s 18us/step - loss: 0.4063 - accuracy: 0.8098\n",
      "Epoch 223/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4021 - accuracy: 0.8054\n",
      "Epoch 224/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4149 - accuracy: 0.7957\n",
      "Epoch 225/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4144 - accuracy: 0.8141\n",
      "Epoch 226/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4071 - accuracy: 0.7913\n",
      "Epoch 227/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4033 - accuracy: 0.8152\n",
      "Epoch 228/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4141 - accuracy: 0.7989\n",
      "Epoch 229/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3994 - accuracy: 0.8163\n",
      "Epoch 230/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4080 - accuracy: 0.8043\n",
      "Epoch 231/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4055 - accuracy: 0.8120\n",
      "Epoch 232/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4029 - accuracy: 0.8109\n",
      "Epoch 233/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4092 - accuracy: 0.7946\n",
      "Epoch 234/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4026 - accuracy: 0.8163\n",
      "Epoch 235/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4039 - accuracy: 0.8120\n",
      "Epoch 236/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4005 - accuracy: 0.8076\n",
      "Epoch 237/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4003 - accuracy: 0.8130\n",
      "Epoch 238/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4076 - accuracy: 0.8120\n",
      "Epoch 239/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4003 - accuracy: 0.8163\n",
      "Epoch 240/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4017 - accuracy: 0.8130\n",
      "Epoch 241/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4114 - accuracy: 0.8087\n",
      "Epoch 242/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4012 - accuracy: 0.8130\n",
      "Epoch 243/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4038 - accuracy: 0.8217\n",
      "Epoch 244/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4071 - accuracy: 0.7946\n",
      "Epoch 245/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4055 - accuracy: 0.8109\n",
      "Epoch 246/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4066 - accuracy: 0.8076\n",
      "Epoch 247/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3976 - accuracy: 0.8065\n",
      "Epoch 248/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4085 - accuracy: 0.8054\n",
      "Epoch 249/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4023 - accuracy: 0.8120\n",
      "Epoch 250/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3958 - accuracy: 0.8217\n",
      "Epoch 251/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4007 - accuracy: 0.8109\n",
      "Epoch 252/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4007 - accuracy: 0.8054\n",
      "Epoch 253/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3998 - accuracy: 0.8152\n",
      "Epoch 254/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3984 - accuracy: 0.8054\n",
      "Epoch 255/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4004 - accuracy: 0.8109\n",
      "Epoch 256/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3981 - accuracy: 0.8130\n",
      "Epoch 257/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3966 - accuracy: 0.8065\n",
      "Epoch 258/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4094 - accuracy: 0.8076\n",
      "Epoch 259/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4090 - accuracy: 0.8022\n",
      "Epoch 260/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3994 - accuracy: 0.8120\n",
      "Epoch 261/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4012 - accuracy: 0.8098\n",
      "Epoch 262/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4027 - accuracy: 0.8120\n",
      "Epoch 263/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3999 - accuracy: 0.8130\n",
      "Epoch 264/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3959 - accuracy: 0.8239\n",
      "Epoch 265/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4032 - accuracy: 0.8011\n",
      "Epoch 266/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4025 - accuracy: 0.8109\n",
      "Epoch 267/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3979 - accuracy: 0.8076\n",
      "Epoch 268/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3990 - accuracy: 0.8120\n",
      "Epoch 269/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3973 - accuracy: 0.8163\n",
      "Epoch 270/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4017 - accuracy: 0.8087\n",
      "Epoch 271/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4056 - accuracy: 0.8054\n",
      "Epoch 272/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4090 - accuracy: 0.8043\n",
      "Epoch 273/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3986 - accuracy: 0.8098\n",
      "Epoch 274/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4097 - accuracy: 0.8000\n",
      "Epoch 275/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4111 - accuracy: 0.7957\n",
      "Epoch 276/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3998 - accuracy: 0.8087\n",
      "Epoch 277/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4131 - accuracy: 0.7880\n",
      "Epoch 278/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3975 - accuracy: 0.8120\n",
      "Epoch 279/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3996 - accuracy: 0.8152\n",
      "Epoch 280/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3999 - accuracy: 0.8152\n",
      "Epoch 281/1000\n",
      "920/920 [==============================] - 0s 15us/step - loss: 0.3944 - accuracy: 0.8087\n",
      "Epoch 282/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4018 - accuracy: 0.8087\n",
      "Epoch 283/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4119 - accuracy: 0.8022\n",
      "Epoch 284/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3949 - accuracy: 0.8130\n",
      "Epoch 285/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3928 - accuracy: 0.8163\n",
      "Epoch 286/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3975 - accuracy: 0.8250\n",
      "Epoch 287/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4025 - accuracy: 0.8098\n",
      "Epoch 288/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4143 - accuracy: 0.8033\n",
      "Epoch 289/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3955 - accuracy: 0.8141\n",
      "Epoch 290/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3953 - accuracy: 0.8109\n",
      "Epoch 291/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4002 - accuracy: 0.8152\n",
      "Epoch 292/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3955 - accuracy: 0.8120\n",
      "Epoch 293/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4049 - accuracy: 0.8043\n",
      "Epoch 294/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4004 - accuracy: 0.8130\n",
      "Epoch 295/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3933 - accuracy: 0.8152\n",
      "Epoch 296/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3982 - accuracy: 0.8065\n",
      "Epoch 297/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3978 - accuracy: 0.8141\n",
      "Epoch 298/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4038 - accuracy: 0.8109\n",
      "Epoch 299/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4039 - accuracy: 0.8000\n",
      "Epoch 300/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3972 - accuracy: 0.8076\n",
      "Epoch 301/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3995 - accuracy: 0.8141\n",
      "Epoch 302/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3921 - accuracy: 0.8130\n",
      "Epoch 303/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3965 - accuracy: 0.8185\n",
      "Epoch 304/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4035 - accuracy: 0.8141\n",
      "Epoch 305/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4003 - accuracy: 0.8196\n",
      "Epoch 306/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3934 - accuracy: 0.8130\n",
      "Epoch 307/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4156 - accuracy: 0.8043\n",
      "Epoch 308/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3940 - accuracy: 0.8076\n",
      "Epoch 309/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3934 - accuracy: 0.8141\n",
      "Epoch 310/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4072 - accuracy: 0.8054\n",
      "Epoch 311/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4099 - accuracy: 0.8087\n",
      "Epoch 312/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4024 - accuracy: 0.8141\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920/920 [==============================] - 0s 16us/step - loss: 0.3921 - accuracy: 0.8207\n",
      "Epoch 314/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4117 - accuracy: 0.8054\n",
      "Epoch 315/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4062 - accuracy: 0.8022\n",
      "Epoch 316/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4023 - accuracy: 0.8098\n",
      "Epoch 317/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3956 - accuracy: 0.8033\n",
      "Epoch 318/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4018 - accuracy: 0.8098\n",
      "Epoch 319/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4097 - accuracy: 0.8141\n",
      "Epoch 320/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4041 - accuracy: 0.8098\n",
      "Epoch 321/1000\n",
      "920/920 [==============================] - ETA: 0s - loss: 0.4647 - accuracy: 0.78 - 0s 16us/step - loss: 0.3938 - accuracy: 0.8109\n",
      "Epoch 322/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3964 - accuracy: 0.8120\n",
      "Epoch 323/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4010 - accuracy: 0.8163\n",
      "Epoch 324/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3976 - accuracy: 0.8065\n",
      "Epoch 325/1000\n",
      "920/920 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.75 - 0s 16us/step - loss: 0.3963 - accuracy: 0.8174\n",
      "Epoch 326/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3983 - accuracy: 0.8098\n",
      "Epoch 327/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3998 - accuracy: 0.8087\n",
      "Epoch 328/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3949 - accuracy: 0.8098\n",
      "Epoch 329/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3953 - accuracy: 0.8196\n",
      "Epoch 330/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3923 - accuracy: 0.8196\n",
      "Epoch 331/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3985 - accuracy: 0.8120\n",
      "Epoch 332/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3926 - accuracy: 0.8130\n",
      "Epoch 333/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4137 - accuracy: 0.8120\n",
      "Epoch 334/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3932 - accuracy: 0.8087\n",
      "Epoch 335/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3955 - accuracy: 0.8087\n",
      "Epoch 336/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3885 - accuracy: 0.8141\n",
      "Epoch 337/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3960 - accuracy: 0.8054\n",
      "Epoch 338/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3922 - accuracy: 0.8120\n",
      "Epoch 339/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4013 - accuracy: 0.8022\n",
      "Epoch 340/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3990 - accuracy: 0.8098\n",
      "Epoch 341/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4033 - accuracy: 0.8087\n",
      "Epoch 342/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3998 - accuracy: 0.8130\n",
      "Epoch 343/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3898 - accuracy: 0.8141\n",
      "Epoch 344/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3970 - accuracy: 0.8120\n",
      "Epoch 345/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3983 - accuracy: 0.8109\n",
      "Epoch 346/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4035 - accuracy: 0.7946\n",
      "Epoch 347/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3964 - accuracy: 0.8141\n",
      "Epoch 348/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3995 - accuracy: 0.8109\n",
      "Epoch 349/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3986 - accuracy: 0.8087\n",
      "Epoch 350/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3958 - accuracy: 0.8152\n",
      "Epoch 351/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3964 - accuracy: 0.8109\n",
      "Epoch 352/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3928 - accuracy: 0.8120\n",
      "Epoch 353/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3923 - accuracy: 0.8174\n",
      "Epoch 354/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3954 - accuracy: 0.8141\n",
      "Epoch 355/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3970 - accuracy: 0.8152\n",
      "Epoch 356/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3964 - accuracy: 0.8152\n",
      "Epoch 357/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4017 - accuracy: 0.8196\n",
      "Epoch 358/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4123 - accuracy: 0.8011\n",
      "Epoch 359/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3908 - accuracy: 0.8152\n",
      "Epoch 360/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4060 - accuracy: 0.8054\n",
      "Epoch 361/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3955 - accuracy: 0.8087\n",
      "Epoch 362/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3870 - accuracy: 0.8185\n",
      "Epoch 363/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3891 - accuracy: 0.8217\n",
      "Epoch 364/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3982 - accuracy: 0.8120\n",
      "Epoch 365/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3919 - accuracy: 0.8141\n",
      "Epoch 366/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4019 - accuracy: 0.7989\n",
      "Epoch 367/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4039 - accuracy: 0.8076\n",
      "Epoch 368/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3934 - accuracy: 0.8185\n",
      "Epoch 369/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3970 - accuracy: 0.8152\n",
      "Epoch 370/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3936 - accuracy: 0.8130\n",
      "Epoch 371/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3966 - accuracy: 0.8130\n",
      "Epoch 372/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3943 - accuracy: 0.8163\n",
      "Epoch 373/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3951 - accuracy: 0.8076\n",
      "Epoch 374/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3907 - accuracy: 0.8109\n",
      "Epoch 375/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3898 - accuracy: 0.8207\n",
      "Epoch 376/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4018 - accuracy: 0.8130\n",
      "Epoch 377/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3984 - accuracy: 0.8087\n",
      "Epoch 378/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4015 - accuracy: 0.8120\n",
      "Epoch 379/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3906 - accuracy: 0.8109\n",
      "Epoch 380/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3919 - accuracy: 0.8109\n",
      "Epoch 381/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3906 - accuracy: 0.8141\n",
      "Epoch 382/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3917 - accuracy: 0.8152\n",
      "Epoch 383/1000\n",
      "920/920 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.71 - 0s 16us/step - loss: 0.3911 - accuracy: 0.8109\n",
      "Epoch 384/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3939 - accuracy: 0.8098\n",
      "Epoch 385/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3902 - accuracy: 0.8141\n",
      "Epoch 386/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3861 - accuracy: 0.8152\n",
      "Epoch 387/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3914 - accuracy: 0.8141\n",
      "Epoch 388/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3907 - accuracy: 0.8141\n",
      "Epoch 389/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3876 - accuracy: 0.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3923 - accuracy: 0.8207\n",
      "Epoch 391/1000\n",
      "920/920 [==============================] - ETA: 0s - loss: 0.4108 - accuracy: 0.81 - 0s 16us/step - loss: 0.3953 - accuracy: 0.8098\n",
      "Epoch 392/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3910 - accuracy: 0.8196\n",
      "Epoch 393/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3918 - accuracy: 0.8196\n",
      "Epoch 394/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4003 - accuracy: 0.8076\n",
      "Epoch 395/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3975 - accuracy: 0.8130\n",
      "Epoch 396/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3926 - accuracy: 0.8163\n",
      "Epoch 397/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3942 - accuracy: 0.8163\n",
      "Epoch 398/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3960 - accuracy: 0.8098\n",
      "Epoch 399/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3881 - accuracy: 0.8272\n",
      "Epoch 400/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3978 - accuracy: 0.8022\n",
      "Epoch 401/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3925 - accuracy: 0.8120\n",
      "Epoch 402/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3918 - accuracy: 0.8174\n",
      "Epoch 403/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3908 - accuracy: 0.8087\n",
      "Epoch 404/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3898 - accuracy: 0.8239\n",
      "Epoch 405/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3925 - accuracy: 0.8120\n",
      "Epoch 406/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3864 - accuracy: 0.8239\n",
      "Epoch 407/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3898 - accuracy: 0.8196\n",
      "Epoch 408/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3906 - accuracy: 0.8207\n",
      "Epoch 409/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3974 - accuracy: 0.8174\n",
      "Epoch 410/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3936 - accuracy: 0.8076\n",
      "Epoch 411/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4051 - accuracy: 0.8076\n",
      "Epoch 412/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4097 - accuracy: 0.8065\n",
      "Epoch 413/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3944 - accuracy: 0.8120\n",
      "Epoch 414/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3915 - accuracy: 0.8152\n",
      "Epoch 415/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3941 - accuracy: 0.8109\n",
      "Epoch 416/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3908 - accuracy: 0.8152\n",
      "Epoch 417/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4009 - accuracy: 0.8130\n",
      "Epoch 418/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3926 - accuracy: 0.8087\n",
      "Epoch 419/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3903 - accuracy: 0.8228\n",
      "Epoch 420/1000\n",
      "920/920 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.84 - 0s 16us/step - loss: 0.3946 - accuracy: 0.8185\n",
      "Epoch 421/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3950 - accuracy: 0.8098\n",
      "Epoch 422/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3902 - accuracy: 0.8141\n",
      "Epoch 423/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4005 - accuracy: 0.8098\n",
      "Epoch 424/1000\n",
      "920/920 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.81 - 0s 16us/step - loss: 0.3912 - accuracy: 0.8109\n",
      "Epoch 425/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3851 - accuracy: 0.8196\n",
      "Epoch 426/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3853 - accuracy: 0.8217\n",
      "Epoch 427/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3926 - accuracy: 0.8250\n",
      "Epoch 428/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3915 - accuracy: 0.8163\n",
      "Epoch 429/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3905 - accuracy: 0.8196\n",
      "Epoch 430/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3869 - accuracy: 0.8196\n",
      "Epoch 431/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3932 - accuracy: 0.8065\n",
      "Epoch 432/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3914 - accuracy: 0.8185\n",
      "Epoch 433/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3838 - accuracy: 0.8228\n",
      "Epoch 434/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3923 - accuracy: 0.8087\n",
      "Epoch 435/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3955 - accuracy: 0.8141\n",
      "Epoch 436/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3892 - accuracy: 0.8141\n",
      "Epoch 437/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3974 - accuracy: 0.8054\n",
      "Epoch 438/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3934 - accuracy: 0.8043\n",
      "Epoch 439/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3877 - accuracy: 0.8130\n",
      "Epoch 440/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3925 - accuracy: 0.8163\n",
      "Epoch 441/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3935 - accuracy: 0.8087\n",
      "Epoch 442/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3886 - accuracy: 0.8185\n",
      "Epoch 443/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3864 - accuracy: 0.8152\n",
      "Epoch 444/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3967 - accuracy: 0.8043\n",
      "Epoch 445/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3894 - accuracy: 0.8087\n",
      "Epoch 446/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3943 - accuracy: 0.8098\n",
      "Epoch 447/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3954 - accuracy: 0.8152\n",
      "Epoch 448/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3895 - accuracy: 0.8130\n",
      "Epoch 449/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3915 - accuracy: 0.8152\n",
      "Epoch 450/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3891 - accuracy: 0.8141\n",
      "Epoch 451/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3876 - accuracy: 0.8098\n",
      "Epoch 452/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3937 - accuracy: 0.8272\n",
      "Epoch 453/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4071 - accuracy: 0.8054\n",
      "Epoch 454/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3894 - accuracy: 0.8174\n",
      "Epoch 455/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3913 - accuracy: 0.8207\n",
      "Epoch 456/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3923 - accuracy: 0.8098\n",
      "Epoch 457/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3920 - accuracy: 0.8217\n",
      "Epoch 458/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4042 - accuracy: 0.8065\n",
      "Epoch 459/1000\n",
      "920/920 [==============================] - ETA: 0s - loss: 0.3698 - accuracy: 0.87 - 0s 16us/step - loss: 0.3908 - accuracy: 0.8152\n",
      "Epoch 460/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3873 - accuracy: 0.8163\n",
      "Epoch 461/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3857 - accuracy: 0.8163\n",
      "Epoch 462/1000\n",
      "920/920 [==============================] - 0s 22us/step - loss: 0.3882 - accuracy: 0.8217\n",
      "Epoch 463/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3899 - accuracy: 0.8185\n",
      "Epoch 464/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3928 - accuracy: 0.8174\n",
      "Epoch 465/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3844 - accuracy: 0.8250\n",
      "Epoch 466/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3918 - accuracy: 0.8152\n",
      "Epoch 467/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3886 - accuracy: 0.8185\n",
      "Epoch 468/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3916 - accuracy: 0.8087\n",
      "Epoch 469/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3867 - accuracy: 0.8163\n",
      "Epoch 470/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4007 - accuracy: 0.8185\n",
      "Epoch 471/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3964 - accuracy: 0.8098\n",
      "Epoch 472/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3861 - accuracy: 0.8228\n",
      "Epoch 473/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3894 - accuracy: 0.8163\n",
      "Epoch 474/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3827 - accuracy: 0.8163\n",
      "Epoch 475/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3857 - accuracy: 0.8185\n",
      "Epoch 476/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3831 - accuracy: 0.8217\n",
      "Epoch 477/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3963 - accuracy: 0.8120\n",
      "Epoch 478/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3862 - accuracy: 0.8261\n",
      "Epoch 479/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3881 - accuracy: 0.8196\n",
      "Epoch 480/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3866 - accuracy: 0.8174\n",
      "Epoch 481/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3872 - accuracy: 0.8217\n",
      "Epoch 482/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3878 - accuracy: 0.8185\n",
      "Epoch 483/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3878 - accuracy: 0.8141\n",
      "Epoch 484/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4168 - accuracy: 0.7989\n",
      "Epoch 485/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4094 - accuracy: 0.8076\n",
      "Epoch 486/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3928 - accuracy: 0.8152\n",
      "Epoch 487/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3926 - accuracy: 0.8109\n",
      "Epoch 488/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3835 - accuracy: 0.8217\n",
      "Epoch 489/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3875 - accuracy: 0.8065\n",
      "Epoch 490/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3893 - accuracy: 0.8163\n",
      "Epoch 491/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3900 - accuracy: 0.8120\n",
      "Epoch 492/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3878 - accuracy: 0.8196\n",
      "Epoch 493/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3910 - accuracy: 0.8152\n",
      "Epoch 494/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3929 - accuracy: 0.8109\n",
      "Epoch 495/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3851 - accuracy: 0.8152\n",
      "Epoch 496/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3998 - accuracy: 0.8109\n",
      "Epoch 497/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3945 - accuracy: 0.8207\n",
      "Epoch 498/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3924 - accuracy: 0.8130\n",
      "Epoch 499/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3923 - accuracy: 0.8076\n",
      "Epoch 500/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3982 - accuracy: 0.8033\n",
      "Epoch 501/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3898 - accuracy: 0.8174\n",
      "Epoch 502/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3922 - accuracy: 0.8098\n",
      "Epoch 503/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3904 - accuracy: 0.8239\n",
      "Epoch 504/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3868 - accuracy: 0.8207\n",
      "Epoch 505/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3913 - accuracy: 0.8163\n",
      "Epoch 506/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3818 - accuracy: 0.8174\n",
      "Epoch 507/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3889 - accuracy: 0.8163\n",
      "Epoch 508/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3839 - accuracy: 0.8130\n",
      "Epoch 509/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3859 - accuracy: 0.8174\n",
      "Epoch 510/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3895 - accuracy: 0.8141\n",
      "Epoch 511/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3860 - accuracy: 0.8239\n",
      "Epoch 512/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3874 - accuracy: 0.8130\n",
      "Epoch 513/1000\n",
      "920/920 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.68 - 0s 16us/step - loss: 0.3857 - accuracy: 0.8185\n",
      "Epoch 514/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3843 - accuracy: 0.8141\n",
      "Epoch 515/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3880 - accuracy: 0.8196\n",
      "Epoch 516/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3852 - accuracy: 0.8185\n",
      "Epoch 517/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3921 - accuracy: 0.8185\n",
      "Epoch 518/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3857 - accuracy: 0.8207\n",
      "Epoch 519/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3837 - accuracy: 0.8217\n",
      "Epoch 520/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3860 - accuracy: 0.8152\n",
      "Epoch 521/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3874 - accuracy: 0.8207\n",
      "Epoch 522/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3899 - accuracy: 0.8076\n",
      "Epoch 523/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3896 - accuracy: 0.8196\n",
      "Epoch 524/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3926 - accuracy: 0.8239\n",
      "Epoch 525/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3879 - accuracy: 0.8141\n",
      "Epoch 526/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3925 - accuracy: 0.8239\n",
      "Epoch 527/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3859 - accuracy: 0.8207\n",
      "Epoch 528/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3874 - accuracy: 0.8120\n",
      "Epoch 529/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3894 - accuracy: 0.8217\n",
      "Epoch 530/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3844 - accuracy: 0.8239\n",
      "Epoch 531/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3878 - accuracy: 0.8174\n",
      "Epoch 532/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3940 - accuracy: 0.8120\n",
      "Epoch 533/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3892 - accuracy: 0.8196\n",
      "Epoch 534/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3885 - accuracy: 0.8196\n",
      "Epoch 535/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3922 - accuracy: 0.8217\n",
      "Epoch 536/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3849 - accuracy: 0.8250\n",
      "Epoch 537/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3867 - accuracy: 0.8185\n",
      "Epoch 538/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3972 - accuracy: 0.8065\n",
      "Epoch 539/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3842 - accuracy: 0.8228\n",
      "Epoch 540/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3883 - accuracy: 0.8174\n",
      "Epoch 541/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3856 - accuracy: 0.8239\n",
      "Epoch 542/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3880 - accuracy: 0.8250\n",
      "Epoch 543/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920/920 [==============================] - 0s 16us/step - loss: 0.3852 - accuracy: 0.8163\n",
      "Epoch 544/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3870 - accuracy: 0.8196\n",
      "Epoch 545/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3846 - accuracy: 0.8217\n",
      "Epoch 546/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3897 - accuracy: 0.8207\n",
      "Epoch 547/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3855 - accuracy: 0.8217\n",
      "Epoch 548/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3847 - accuracy: 0.8163\n",
      "Epoch 549/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3897 - accuracy: 0.8109\n",
      "Epoch 550/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3882 - accuracy: 0.8174\n",
      "Epoch 551/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3906 - accuracy: 0.8141\n",
      "Epoch 552/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3830 - accuracy: 0.8207\n",
      "Epoch 553/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3941 - accuracy: 0.8130\n",
      "Epoch 554/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3939 - accuracy: 0.8185\n",
      "Epoch 555/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3933 - accuracy: 0.8087\n",
      "Epoch 556/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3883 - accuracy: 0.8098\n",
      "Epoch 557/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3943 - accuracy: 0.8130\n",
      "Epoch 558/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3900 - accuracy: 0.8228\n",
      "Epoch 559/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3849 - accuracy: 0.8109\n",
      "Epoch 560/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3843 - accuracy: 0.8272\n",
      "Epoch 561/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3943 - accuracy: 0.8152\n",
      "Epoch 562/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3947 - accuracy: 0.8098\n",
      "Epoch 563/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3937 - accuracy: 0.8185\n",
      "Epoch 564/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3893 - accuracy: 0.8228\n",
      "Epoch 565/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3846 - accuracy: 0.8217\n",
      "Epoch 566/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3827 - accuracy: 0.8239\n",
      "Epoch 567/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3887 - accuracy: 0.8185\n",
      "Epoch 568/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3880 - accuracy: 0.8141\n",
      "Epoch 569/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3937 - accuracy: 0.8098\n",
      "Epoch 570/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3970 - accuracy: 0.8174\n",
      "Epoch 571/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3935 - accuracy: 0.8109\n",
      "Epoch 572/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3933 - accuracy: 0.8130\n",
      "Epoch 573/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3850 - accuracy: 0.8152\n",
      "Epoch 574/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3813 - accuracy: 0.8239\n",
      "Epoch 575/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3922 - accuracy: 0.8120\n",
      "Epoch 576/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3874 - accuracy: 0.8109\n",
      "Epoch 577/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3815 - accuracy: 0.8174\n",
      "Epoch 578/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3868 - accuracy: 0.8120\n",
      "Epoch 579/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3852 - accuracy: 0.8283\n",
      "Epoch 580/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3822 - accuracy: 0.8228\n",
      "Epoch 581/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3829 - accuracy: 0.8174\n",
      "Epoch 582/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3958 - accuracy: 0.8033\n",
      "Epoch 583/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3870 - accuracy: 0.8228\n",
      "Epoch 584/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3850 - accuracy: 0.8163\n",
      "Epoch 585/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3877 - accuracy: 0.8130\n",
      "Epoch 586/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3835 - accuracy: 0.8120\n",
      "Epoch 587/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3860 - accuracy: 0.8130\n",
      "Epoch 588/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3966 - accuracy: 0.8120\n",
      "Epoch 589/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3877 - accuracy: 0.8185\n",
      "Epoch 590/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3803 - accuracy: 0.8239\n",
      "Epoch 591/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3837 - accuracy: 0.8163\n",
      "Epoch 592/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3866 - accuracy: 0.8163\n",
      "Epoch 593/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3846 - accuracy: 0.8283\n",
      "Epoch 594/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3898 - accuracy: 0.8130\n",
      "Epoch 595/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3841 - accuracy: 0.8207\n",
      "Epoch 596/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3848 - accuracy: 0.8228\n",
      "Epoch 597/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3843 - accuracy: 0.8239\n",
      "Epoch 598/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3812 - accuracy: 0.8207\n",
      "Epoch 599/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3855 - accuracy: 0.8141\n",
      "Epoch 600/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3930 - accuracy: 0.8152\n",
      "Epoch 601/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3875 - accuracy: 0.8217\n",
      "Epoch 602/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3908 - accuracy: 0.8152\n",
      "Epoch 603/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3831 - accuracy: 0.8174\n",
      "Epoch 604/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3895 - accuracy: 0.8185\n",
      "Epoch 605/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3873 - accuracy: 0.8054\n",
      "Epoch 606/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3832 - accuracy: 0.8185\n",
      "Epoch 607/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3831 - accuracy: 0.8272\n",
      "Epoch 608/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3818 - accuracy: 0.8207\n",
      "Epoch 609/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3800 - accuracy: 0.8163\n",
      "Epoch 610/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3780 - accuracy: 0.8261\n",
      "Epoch 611/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3796 - accuracy: 0.8196\n",
      "Epoch 612/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3889 - accuracy: 0.8163\n",
      "Epoch 613/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3851 - accuracy: 0.8196\n",
      "Epoch 614/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3871 - accuracy: 0.8217\n",
      "Epoch 615/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3807 - accuracy: 0.8207\n",
      "Epoch 616/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3868 - accuracy: 0.8109\n",
      "Epoch 617/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3884 - accuracy: 0.8250\n",
      "Epoch 618/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3911 - accuracy: 0.8054\n",
      "Epoch 619/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3885 - accuracy: 0.8163\n",
      "Epoch 620/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3852 - accuracy: 0.8163\n",
      "Epoch 621/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3868 - accuracy: 0.8065\n",
      "Epoch 622/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3869 - accuracy: 0.8098\n",
      "Epoch 623/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3882 - accuracy: 0.8239\n",
      "Epoch 624/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3803 - accuracy: 0.8239\n",
      "Epoch 625/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3783 - accuracy: 0.8185\n",
      "Epoch 626/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3843 - accuracy: 0.8185\n",
      "Epoch 627/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3912 - accuracy: 0.8196\n",
      "Epoch 628/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3829 - accuracy: 0.8217\n",
      "Epoch 629/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3910 - accuracy: 0.8163\n",
      "Epoch 630/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3891 - accuracy: 0.8130\n",
      "Epoch 631/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3919 - accuracy: 0.8207\n",
      "Epoch 632/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3844 - accuracy: 0.8293\n",
      "Epoch 633/1000\n",
      "920/920 [==============================] - 0s 18us/step - loss: 0.3801 - accuracy: 0.8207\n",
      "Epoch 634/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3814 - accuracy: 0.8250\n",
      "Epoch 635/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3845 - accuracy: 0.8207\n",
      "Epoch 636/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3819 - accuracy: 0.8163\n",
      "Epoch 637/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3850 - accuracy: 0.8283\n",
      "Epoch 638/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3853 - accuracy: 0.8174\n",
      "Epoch 639/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3840 - accuracy: 0.8228\n",
      "Epoch 640/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3824 - accuracy: 0.8228\n",
      "Epoch 641/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3856 - accuracy: 0.8141\n",
      "Epoch 642/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3796 - accuracy: 0.8185\n",
      "Epoch 643/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3836 - accuracy: 0.8174\n",
      "Epoch 644/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3891 - accuracy: 0.8141\n",
      "Epoch 645/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3849 - accuracy: 0.8185\n",
      "Epoch 646/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3896 - accuracy: 0.8120\n",
      "Epoch 647/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3830 - accuracy: 0.8261\n",
      "Epoch 648/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3831 - accuracy: 0.8239\n",
      "Epoch 649/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3792 - accuracy: 0.8250\n",
      "Epoch 650/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3771 - accuracy: 0.8250\n",
      "Epoch 651/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3829 - accuracy: 0.8196\n",
      "Epoch 652/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3793 - accuracy: 0.8261\n",
      "Epoch 653/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3836 - accuracy: 0.8261\n",
      "Epoch 654/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3864 - accuracy: 0.8217\n",
      "Epoch 655/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3805 - accuracy: 0.8185\n",
      "Epoch 656/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3800 - accuracy: 0.8283\n",
      "Epoch 657/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3873 - accuracy: 0.8174\n",
      "Epoch 658/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3789 - accuracy: 0.8261\n",
      "Epoch 659/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3799 - accuracy: 0.8293\n",
      "Epoch 660/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3791 - accuracy: 0.8185\n",
      "Epoch 661/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3799 - accuracy: 0.8207\n",
      "Epoch 662/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3791 - accuracy: 0.8185\n",
      "Epoch 663/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3845 - accuracy: 0.8152\n",
      "Epoch 664/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3814 - accuracy: 0.8207\n",
      "Epoch 665/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3828 - accuracy: 0.8228\n",
      "Epoch 666/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3815 - accuracy: 0.8185\n",
      "Epoch 667/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3894 - accuracy: 0.8174\n",
      "Epoch 668/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3825 - accuracy: 0.8272\n",
      "Epoch 669/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3814 - accuracy: 0.8261\n",
      "Epoch 670/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3853 - accuracy: 0.8174\n",
      "Epoch 671/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3791 - accuracy: 0.8261\n",
      "Epoch 672/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3792 - accuracy: 0.8196\n",
      "Epoch 673/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3804 - accuracy: 0.8228\n",
      "Epoch 674/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3882 - accuracy: 0.8098\n",
      "Epoch 675/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3838 - accuracy: 0.8152\n",
      "Epoch 676/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3793 - accuracy: 0.8228\n",
      "Epoch 677/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3781 - accuracy: 0.8196\n",
      "Epoch 678/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3923 - accuracy: 0.8033\n",
      "Epoch 679/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3810 - accuracy: 0.8228\n",
      "Epoch 680/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3848 - accuracy: 0.8185\n",
      "Epoch 681/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3878 - accuracy: 0.8130\n",
      "Epoch 682/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3794 - accuracy: 0.8174\n",
      "Epoch 683/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3843 - accuracy: 0.8272\n",
      "Epoch 684/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3807 - accuracy: 0.8250\n",
      "Epoch 685/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3910 - accuracy: 0.8065\n",
      "Epoch 686/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3882 - accuracy: 0.8228\n",
      "Epoch 687/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3927 - accuracy: 0.8076\n",
      "Epoch 688/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3773 - accuracy: 0.8228\n",
      "Epoch 689/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3776 - accuracy: 0.8228\n",
      "Epoch 690/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3788 - accuracy: 0.8174\n",
      "Epoch 691/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3829 - accuracy: 0.8174\n",
      "Epoch 692/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3773 - accuracy: 0.8283\n",
      "Epoch 693/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3834 - accuracy: 0.8141\n",
      "Epoch 694/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3846 - accuracy: 0.8130\n",
      "Epoch 695/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3773 - accuracy: 0.8196\n",
      "Epoch 696/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3812 - accuracy: 0.8196\n",
      "Epoch 697/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3790 - accuracy: 0.8174\n",
      "Epoch 698/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3801 - accuracy: 0.8228\n",
      "Epoch 699/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920/920 [==============================] - 0s 16us/step - loss: 0.3751 - accuracy: 0.8185\n",
      "Epoch 700/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3801 - accuracy: 0.8152\n",
      "Epoch 701/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3778 - accuracy: 0.8207\n",
      "Epoch 702/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3806 - accuracy: 0.8217\n",
      "Epoch 703/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3769 - accuracy: 0.8196\n",
      "Epoch 704/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3991 - accuracy: 0.8098\n",
      "Epoch 705/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3903 - accuracy: 0.8152\n",
      "Epoch 706/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3775 - accuracy: 0.8217\n",
      "Epoch 707/1000\n",
      "920/920 [==============================] - 0s 21us/step - loss: 0.3895 - accuracy: 0.8239\n",
      "Epoch 708/1000\n",
      "920/920 [==============================] - 0s 18us/step - loss: 0.3913 - accuracy: 0.8109\n",
      "Epoch 709/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3891 - accuracy: 0.8250\n",
      "Epoch 710/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3807 - accuracy: 0.8239\n",
      "Epoch 711/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3753 - accuracy: 0.8250\n",
      "Epoch 712/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3789 - accuracy: 0.8174\n",
      "Epoch 713/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3810 - accuracy: 0.8196\n",
      "Epoch 714/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3783 - accuracy: 0.8207\n",
      "Epoch 715/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3818 - accuracy: 0.8207\n",
      "Epoch 716/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3933 - accuracy: 0.8217\n",
      "Epoch 717/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3839 - accuracy: 0.8152\n",
      "Epoch 718/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3846 - accuracy: 0.8217\n",
      "Epoch 719/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3834 - accuracy: 0.8228\n",
      "Epoch 720/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3861 - accuracy: 0.8120\n",
      "Epoch 721/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3770 - accuracy: 0.8283\n",
      "Epoch 722/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3842 - accuracy: 0.8174\n",
      "Epoch 723/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3801 - accuracy: 0.8163\n",
      "Epoch 724/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3808 - accuracy: 0.8207\n",
      "Epoch 725/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3776 - accuracy: 0.8261\n",
      "Epoch 726/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3748 - accuracy: 0.8196\n",
      "Epoch 727/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3810 - accuracy: 0.8196\n",
      "Epoch 728/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3836 - accuracy: 0.8250\n",
      "Epoch 729/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3872 - accuracy: 0.8185\n",
      "Epoch 730/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3808 - accuracy: 0.8272\n",
      "Epoch 731/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3827 - accuracy: 0.8207\n",
      "Epoch 732/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3798 - accuracy: 0.8228\n",
      "Epoch 733/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3884 - accuracy: 0.8239\n",
      "Epoch 734/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3843 - accuracy: 0.8163\n",
      "Epoch 735/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3799 - accuracy: 0.8109\n",
      "Epoch 736/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3773 - accuracy: 0.8239\n",
      "Epoch 737/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3825 - accuracy: 0.8163\n",
      "Epoch 738/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3833 - accuracy: 0.8207\n",
      "Epoch 739/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3806 - accuracy: 0.8283\n",
      "Epoch 740/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3820 - accuracy: 0.8250\n",
      "Epoch 741/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3774 - accuracy: 0.8196\n",
      "Epoch 742/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3812 - accuracy: 0.8152\n",
      "Epoch 743/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3804 - accuracy: 0.8152\n",
      "Epoch 744/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3776 - accuracy: 0.8217\n",
      "Epoch 745/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3793 - accuracy: 0.8174\n",
      "Epoch 746/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3803 - accuracy: 0.8130\n",
      "Epoch 747/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3797 - accuracy: 0.8283\n",
      "Epoch 748/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3756 - accuracy: 0.8207\n",
      "Epoch 749/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3838 - accuracy: 0.8109\n",
      "Epoch 750/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3830 - accuracy: 0.8174\n",
      "Epoch 751/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3765 - accuracy: 0.8272\n",
      "Epoch 752/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3774 - accuracy: 0.8239\n",
      "Epoch 753/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3813 - accuracy: 0.8120\n",
      "Epoch 754/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3857 - accuracy: 0.8174\n",
      "Epoch 755/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3864 - accuracy: 0.8185\n",
      "Epoch 756/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3827 - accuracy: 0.8163\n",
      "Epoch 757/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3859 - accuracy: 0.8163\n",
      "Epoch 758/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3754 - accuracy: 0.8228\n",
      "Epoch 759/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3775 - accuracy: 0.8239\n",
      "Epoch 760/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3808 - accuracy: 0.8261\n",
      "Epoch 761/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3797 - accuracy: 0.8174\n",
      "Epoch 762/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3814 - accuracy: 0.8217\n",
      "Epoch 763/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3847 - accuracy: 0.8130\n",
      "Epoch 764/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3771 - accuracy: 0.8261\n",
      "Epoch 765/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3788 - accuracy: 0.8228\n",
      "Epoch 766/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3863 - accuracy: 0.8141\n",
      "Epoch 767/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3810 - accuracy: 0.8217\n",
      "Epoch 768/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3754 - accuracy: 0.8239\n",
      "Epoch 769/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3778 - accuracy: 0.8217\n",
      "Epoch 770/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3779 - accuracy: 0.8228\n",
      "Epoch 771/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3802 - accuracy: 0.8141\n",
      "Epoch 772/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3809 - accuracy: 0.8163\n",
      "Epoch 773/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3768 - accuracy: 0.8207\n",
      "Epoch 774/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3833 - accuracy: 0.8196\n",
      "Epoch 775/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3823 - accuracy: 0.8130\n",
      "Epoch 776/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3851 - accuracy: 0.8207\n",
      "Epoch 777/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3899 - accuracy: 0.8152\n",
      "Epoch 778/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3802 - accuracy: 0.8283\n",
      "Epoch 779/1000\n",
      "920/920 [==============================] - 0s 15us/step - loss: 0.3751 - accuracy: 0.8196\n",
      "Epoch 780/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3775 - accuracy: 0.8174\n",
      "Epoch 781/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3827 - accuracy: 0.8250\n",
      "Epoch 782/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3801 - accuracy: 0.8174\n",
      "Epoch 783/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3785 - accuracy: 0.8217\n",
      "Epoch 784/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3828 - accuracy: 0.8174\n",
      "Epoch 785/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3785 - accuracy: 0.8261\n",
      "Epoch 786/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3857 - accuracy: 0.8207\n",
      "Epoch 787/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3818 - accuracy: 0.8163\n",
      "Epoch 788/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3800 - accuracy: 0.8207\n",
      "Epoch 789/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3748 - accuracy: 0.8250\n",
      "Epoch 790/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3754 - accuracy: 0.8315\n",
      "Epoch 791/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3824 - accuracy: 0.8283\n",
      "Epoch 792/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3796 - accuracy: 0.8228\n",
      "Epoch 793/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3760 - accuracy: 0.8185\n",
      "Epoch 794/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3729 - accuracy: 0.8283\n",
      "Epoch 795/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3799 - accuracy: 0.8207\n",
      "Epoch 796/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3780 - accuracy: 0.8217\n",
      "Epoch 797/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3787 - accuracy: 0.8359\n",
      "Epoch 798/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3772 - accuracy: 0.8217\n",
      "Epoch 799/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3734 - accuracy: 0.8239\n",
      "Epoch 800/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3824 - accuracy: 0.8217\n",
      "Epoch 801/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3859 - accuracy: 0.8185\n",
      "Epoch 802/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3765 - accuracy: 0.8250\n",
      "Epoch 803/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3763 - accuracy: 0.8228\n",
      "Epoch 804/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3770 - accuracy: 0.8272\n",
      "Epoch 805/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3781 - accuracy: 0.8196\n",
      "Epoch 806/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3764 - accuracy: 0.8272\n",
      "Epoch 807/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3810 - accuracy: 0.8174\n",
      "Epoch 808/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3815 - accuracy: 0.8076\n",
      "Epoch 809/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3739 - accuracy: 0.8283\n",
      "Epoch 810/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3831 - accuracy: 0.8196\n",
      "Epoch 811/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3850 - accuracy: 0.8283\n",
      "Epoch 812/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3784 - accuracy: 0.8326\n",
      "Epoch 813/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3772 - accuracy: 0.8109\n",
      "Epoch 814/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3779 - accuracy: 0.8293\n",
      "Epoch 815/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3763 - accuracy: 0.8228\n",
      "Epoch 816/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3804 - accuracy: 0.8196\n",
      "Epoch 817/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3824 - accuracy: 0.8250\n",
      "Epoch 818/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3726 - accuracy: 0.8304\n",
      "Epoch 819/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3818 - accuracy: 0.8130\n",
      "Epoch 820/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3776 - accuracy: 0.8196\n",
      "Epoch 821/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3766 - accuracy: 0.8250\n",
      "Epoch 822/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3737 - accuracy: 0.8272\n",
      "Epoch 823/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3771 - accuracy: 0.8217\n",
      "Epoch 824/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3878 - accuracy: 0.8141\n",
      "Epoch 825/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3797 - accuracy: 0.8250\n",
      "Epoch 826/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3785 - accuracy: 0.8217\n",
      "Epoch 827/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3744 - accuracy: 0.8283\n",
      "Epoch 828/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3769 - accuracy: 0.8152\n",
      "Epoch 829/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3766 - accuracy: 0.8293\n",
      "Epoch 830/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3807 - accuracy: 0.8217\n",
      "Epoch 831/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3776 - accuracy: 0.8207\n",
      "Epoch 832/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3795 - accuracy: 0.8217\n",
      "Epoch 833/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3739 - accuracy: 0.8261\n",
      "Epoch 834/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3750 - accuracy: 0.8196\n",
      "Epoch 835/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3811 - accuracy: 0.8130\n",
      "Epoch 836/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3804 - accuracy: 0.8293\n",
      "Epoch 837/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3824 - accuracy: 0.8283\n",
      "Epoch 838/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3802 - accuracy: 0.8250\n",
      "Epoch 839/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3769 - accuracy: 0.8315\n",
      "Epoch 840/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3825 - accuracy: 0.8207\n",
      "Epoch 841/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3792 - accuracy: 0.8185\n",
      "Epoch 842/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3806 - accuracy: 0.8272\n",
      "Epoch 843/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3744 - accuracy: 0.8250\n",
      "Epoch 844/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3860 - accuracy: 0.8207\n",
      "Epoch 845/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3954 - accuracy: 0.8120\n",
      "Epoch 846/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3802 - accuracy: 0.8207\n",
      "Epoch 847/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3817 - accuracy: 0.8207\n",
      "Epoch 848/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3765 - accuracy: 0.8217\n",
      "Epoch 849/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3750 - accuracy: 0.8228\n",
      "Epoch 850/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3771 - accuracy: 0.8185\n",
      "Epoch 851/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3816 - accuracy: 0.8130\n",
      "Epoch 852/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3758 - accuracy: 0.8272\n",
      "Epoch 853/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3749 - accuracy: 0.8239\n",
      "Epoch 854/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3869 - accuracy: 0.8163\n",
      "Epoch 855/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920/920 [==============================] - 0s 16us/step - loss: 0.3734 - accuracy: 0.8272\n",
      "Epoch 856/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3801 - accuracy: 0.8228\n",
      "Epoch 857/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3761 - accuracy: 0.8261\n",
      "Epoch 858/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.4045 - accuracy: 0.8043\n",
      "Epoch 859/1000\n",
      "920/920 [==============================] - 0s 18us/step - loss: 0.3825 - accuracy: 0.8261\n",
      "Epoch 860/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3787 - accuracy: 0.8217\n",
      "Epoch 861/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3763 - accuracy: 0.8185\n",
      "Epoch 862/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3778 - accuracy: 0.8293\n",
      "Epoch 863/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3776 - accuracy: 0.8207\n",
      "Epoch 864/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3719 - accuracy: 0.8272\n",
      "Epoch 865/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3844 - accuracy: 0.8228\n",
      "Epoch 866/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3727 - accuracy: 0.8293\n",
      "Epoch 867/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.4046 - accuracy: 0.8011\n",
      "Epoch 868/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3772 - accuracy: 0.8250\n",
      "Epoch 869/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3765 - accuracy: 0.8152\n",
      "Epoch 870/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3838 - accuracy: 0.8272\n",
      "Epoch 871/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3873 - accuracy: 0.8022\n",
      "Epoch 872/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3804 - accuracy: 0.8217\n",
      "Epoch 873/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3744 - accuracy: 0.8228\n",
      "Epoch 874/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3779 - accuracy: 0.8293\n",
      "Epoch 875/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3745 - accuracy: 0.8185\n",
      "Epoch 876/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3779 - accuracy: 0.8239\n",
      "Epoch 877/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3784 - accuracy: 0.8315\n",
      "Epoch 878/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3780 - accuracy: 0.8228\n",
      "Epoch 879/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3798 - accuracy: 0.8174\n",
      "Epoch 880/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3759 - accuracy: 0.8196\n",
      "Epoch 881/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3723 - accuracy: 0.8348\n",
      "Epoch 882/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3784 - accuracy: 0.8304\n",
      "Epoch 883/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3792 - accuracy: 0.8120\n",
      "Epoch 884/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3778 - accuracy: 0.8239\n",
      "Epoch 885/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3758 - accuracy: 0.8239\n",
      "Epoch 886/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3776 - accuracy: 0.8196\n",
      "Epoch 887/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3792 - accuracy: 0.8228\n",
      "Epoch 888/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3752 - accuracy: 0.8228\n",
      "Epoch 889/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3779 - accuracy: 0.8261\n",
      "Epoch 890/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3772 - accuracy: 0.8152\n",
      "Epoch 891/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3745 - accuracy: 0.8217\n",
      "Epoch 892/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3707 - accuracy: 0.8272\n",
      "Epoch 893/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3808 - accuracy: 0.8185\n",
      "Epoch 894/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3787 - accuracy: 0.8163\n",
      "Epoch 895/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3857 - accuracy: 0.8163\n",
      "Epoch 896/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3807 - accuracy: 0.8152\n",
      "Epoch 897/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3784 - accuracy: 0.8207\n",
      "Epoch 898/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3774 - accuracy: 0.8272\n",
      "Epoch 899/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3719 - accuracy: 0.8272\n",
      "Epoch 900/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3742 - accuracy: 0.8283\n",
      "Epoch 901/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3772 - accuracy: 0.8239\n",
      "Epoch 902/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3786 - accuracy: 0.8315\n",
      "Epoch 903/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3760 - accuracy: 0.8152\n",
      "Epoch 904/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3824 - accuracy: 0.8196\n",
      "Epoch 905/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3793 - accuracy: 0.8326\n",
      "Epoch 906/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3919 - accuracy: 0.8109\n",
      "Epoch 907/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3792 - accuracy: 0.8250\n",
      "Epoch 908/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3749 - accuracy: 0.8207\n",
      "Epoch 909/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3783 - accuracy: 0.8261\n",
      "Epoch 910/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3782 - accuracy: 0.8283\n",
      "Epoch 911/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3732 - accuracy: 0.8163\n",
      "Epoch 912/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3750 - accuracy: 0.8261\n",
      "Epoch 913/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3726 - accuracy: 0.8239\n",
      "Epoch 914/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3779 - accuracy: 0.8163\n",
      "Epoch 915/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3793 - accuracy: 0.8185\n",
      "Epoch 916/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3872 - accuracy: 0.8152\n",
      "Epoch 917/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3714 - accuracy: 0.8272\n",
      "Epoch 918/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3748 - accuracy: 0.8272\n",
      "Epoch 919/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3769 - accuracy: 0.8217\n",
      "Epoch 920/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3745 - accuracy: 0.8228\n",
      "Epoch 921/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3958 - accuracy: 0.8054\n",
      "Epoch 922/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3789 - accuracy: 0.8261\n",
      "Epoch 923/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3842 - accuracy: 0.8207\n",
      "Epoch 924/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3750 - accuracy: 0.8207\n",
      "Epoch 925/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3812 - accuracy: 0.8228\n",
      "Epoch 926/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3740 - accuracy: 0.8272\n",
      "Epoch 927/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3762 - accuracy: 0.8185\n",
      "Epoch 928/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3762 - accuracy: 0.8293\n",
      "Epoch 929/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3764 - accuracy: 0.8228\n",
      "Epoch 930/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3780 - accuracy: 0.8239\n",
      "Epoch 931/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3835 - accuracy: 0.8293\n",
      "Epoch 932/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3805 - accuracy: 0.8141\n",
      "Epoch 933/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3756 - accuracy: 0.8272\n",
      "Epoch 934/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3735 - accuracy: 0.8272\n",
      "Epoch 935/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3839 - accuracy: 0.8163\n",
      "Epoch 936/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3777 - accuracy: 0.8130\n",
      "Epoch 937/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3798 - accuracy: 0.8207\n",
      "Epoch 938/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3778 - accuracy: 0.8174\n",
      "Epoch 939/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3748 - accuracy: 0.8293\n",
      "Epoch 940/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3898 - accuracy: 0.8217\n",
      "Epoch 941/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3834 - accuracy: 0.8217\n",
      "Epoch 942/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3752 - accuracy: 0.8207\n",
      "Epoch 943/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3847 - accuracy: 0.8141\n",
      "Epoch 944/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3742 - accuracy: 0.8283\n",
      "Epoch 945/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3753 - accuracy: 0.8228\n",
      "Epoch 946/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3777 - accuracy: 0.8272\n",
      "Epoch 947/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3739 - accuracy: 0.8293\n",
      "Epoch 948/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3840 - accuracy: 0.8250\n",
      "Epoch 949/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3725 - accuracy: 0.8239\n",
      "Epoch 950/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3718 - accuracy: 0.8250\n",
      "Epoch 951/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3786 - accuracy: 0.8337\n",
      "Epoch 952/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3721 - accuracy: 0.8207\n",
      "Epoch 953/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3720 - accuracy: 0.8315\n",
      "Epoch 954/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3770 - accuracy: 0.8152\n",
      "Epoch 955/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3723 - accuracy: 0.8217\n",
      "Epoch 956/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3751 - accuracy: 0.8283\n",
      "Epoch 957/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3823 - accuracy: 0.8207\n",
      "Epoch 958/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3819 - accuracy: 0.8196\n",
      "Epoch 959/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3818 - accuracy: 0.8239\n",
      "Epoch 960/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3732 - accuracy: 0.8250\n",
      "Epoch 961/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3748 - accuracy: 0.8370\n",
      "Epoch 962/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3807 - accuracy: 0.8098\n",
      "Epoch 963/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3882 - accuracy: 0.8228\n",
      "Epoch 964/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3788 - accuracy: 0.8228\n",
      "Epoch 965/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3790 - accuracy: 0.8185\n",
      "Epoch 966/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3779 - accuracy: 0.8217\n",
      "Epoch 967/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3838 - accuracy: 0.8272\n",
      "Epoch 968/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3811 - accuracy: 0.8228\n",
      "Epoch 969/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3883 - accuracy: 0.8217\n",
      "Epoch 970/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3720 - accuracy: 0.8217\n",
      "Epoch 971/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3742 - accuracy: 0.8239\n",
      "Epoch 972/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3796 - accuracy: 0.8304\n",
      "Epoch 973/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3882 - accuracy: 0.8163\n",
      "Epoch 974/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3735 - accuracy: 0.8283\n",
      "Epoch 975/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3752 - accuracy: 0.8293\n",
      "Epoch 976/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3775 - accuracy: 0.8174\n",
      "Epoch 977/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3760 - accuracy: 0.8337\n",
      "Epoch 978/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3796 - accuracy: 0.8130\n",
      "Epoch 979/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3789 - accuracy: 0.8239\n",
      "Epoch 980/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3760 - accuracy: 0.8217\n",
      "Epoch 981/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3861 - accuracy: 0.8228\n",
      "Epoch 982/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3711 - accuracy: 0.8304\n",
      "Epoch 983/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3898 - accuracy: 0.8163\n",
      "Epoch 984/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3824 - accuracy: 0.8185\n",
      "Epoch 985/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3871 - accuracy: 0.8228\n",
      "Epoch 986/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3703 - accuracy: 0.8261\n",
      "Epoch 987/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3759 - accuracy: 0.8261\n",
      "Epoch 988/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3759 - accuracy: 0.8293\n",
      "Epoch 989/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3777 - accuracy: 0.8185\n",
      "Epoch 990/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3736 - accuracy: 0.8283\n",
      "Epoch 991/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3776 - accuracy: 0.8196\n",
      "Epoch 992/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3733 - accuracy: 0.8250\n",
      "Epoch 993/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3709 - accuracy: 0.8293\n",
      "Epoch 994/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3744 - accuracy: 0.8293\n",
      "Epoch 995/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3735 - accuracy: 0.8272\n",
      "Epoch 996/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3780 - accuracy: 0.8293\n",
      "Epoch 997/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3752 - accuracy: 0.8283\n",
      "Epoch 998/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3743 - accuracy: 0.8326\n",
      "Epoch 999/1000\n",
      "920/920 [==============================] - 0s 16us/step - loss: 0.3745 - accuracy: 0.8196\n",
      "Epoch 1000/1000\n",
      "920/920 [==============================] - 0s 17us/step - loss: 0.3803 - accuracy: 0.8217\n"
     ]
    }
   ],
   "source": [
    "# neural network\n",
    "\n",
    "\n",
    "adam = Adam(lr=0.01)\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(5, activation='sigmoid',\n",
    "                     kernel_initializer='random_normal', input_dim=19))\n",
    "classifier.add(Dense(5, activation='sigmoid',\n",
    "                     kernel_initializer='random_normal'))\n",
    "classifier.add(Dense(5, activation='sigmoid',\n",
    "                     kernel_initializer='random_normal'))\n",
    "classifier.add(Dense(1, activation='sigmoid',\n",
    "                     kernel_initializer='random_normal'))\n",
    "classifier.compile(\n",
    "    optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "classifier.fit(data_train, target_train, epochs=1000)\n",
    "\n",
    "prednn = classifier.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:37:44.611190Z",
     "start_time": "2020-05-16T10:37:44.607718Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OEbNu9CIOYY5",
    "outputId": "b41f7f9b-fcae-440e-922d-df28f547ec15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN accuracy:  0.7359307359307359\n"
     ]
    }
   ],
   "source": [
    "prednn = (prednn > 0.5)\n",
    "print(\"NN accuracy: \", accuracy_score(target_test, prednn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:37:44.625078Z",
     "start_time": "2020-05-16T10:37:44.612182Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ovkqpx0rOYY7",
    "outputId": "58a8430c-301a-47d2-a76f-2fa81a7b6e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT accuracy:  0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "# DT\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(data_train,  target_train)\n",
    "\n",
    "pred = dt.predict(data_test)\n",
    "\n",
    "print(\"DT accuracy: \", accuracy_score(target_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:37:44.722790Z",
     "start_time": "2020-05-16T10:37:44.626070Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "IrubU5R9FU9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.658008658008658\n"
     ]
    }
   ],
   "source": [
    "AdaBoost = AdaBoostClassifier(learning_rate=1)\n",
    "AdaBoost.fit(data_train, target_train)\n",
    "print(AdaBoost.score(data_test, target_test))\n",
    "prediction_AdaBoost = AdaBoost.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:37:44.738165Z",
     "start_time": "2020-05-16T10:37:44.723782Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multioutput target data is not supported with label binarization",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-bc8c78dd8850>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m clf = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,\n\u001b[0;32m      2\u001b[0m                      solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MLP accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    993\u001b[0m         \"\"\"\n\u001b[0;32m    994\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[1;32m--> 995\u001b[1;33m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    323\u001b[0m                              hidden_layer_sizes)\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    936\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_type_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'multioutput'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_type_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m             raise ValueError(\"Multioutput target data is not supported with \"\n\u001b[0m\u001b[0;32m    427\u001b[0m                              \"label binarization\")\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Multioutput target data is not supported with label binarization"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=500, alpha=0.0001,\n",
    "                    solver='sgd', verbose=10,  random_state=21, tol=0.000000001)\n",
    "clf.fit(data_train, data_train)\n",
    "pred = clf.predict(data_test)\n",
    "print(\"MLP accuracy: \", accuracy_score(target_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Rethinopathy.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
